{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "146kyw-c57v7ong5EecRkobirM7-7JbVY",
      "authorship_tag": "ABX9TyMvcZ5OcbyMb0wr/TSSyCho",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohisa302/Lane-detection/blob/master/Copy_of_detectingline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mql8N1VJpawS",
        "outputId": "238ba833-4d0e-4ec8-b27c-fbb9435b9354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▎                          | 10 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 20 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 30 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 40 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61 kB 492 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from np_utils) (1.19.5)\n",
            "Building wheels for collected packages: np-utils\n",
            "  Building wheel for np-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np-utils: filename=np_utils-0.6.0-py3-none-any.whl size=56459 sha256=577deba6697ca018dc73d3e79f696195795b169c8ffc78c980cdaa5316df557b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/83/71/a781667865955ae7dc18e5a4038401deb56d96eb85d3a5f1c0\n",
            "Successfully built np-utils\n",
            "Installing collected packages: np-utils\n",
            "Successfully installed np-utils-0.6.0\n",
            "['.config', 'drive', 'data', 'self driving car training data', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "from __future__ import division\n",
        "import random\n",
        "from keras.callbacks import History\n",
        "from keras.layers import Dense, Activation, Flatten, Conv2D, Lambda\n",
        "from keras.layers import MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "import keras.backend as K\n",
        "import pickle\n",
        "import csv\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import islice\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import load_model\n",
        "import keras.utils\n",
        "\n",
        "#For Visualizations\n",
        "from scipy.stats import norm, skew\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from __future__ import division\n",
        "import random,pickle,csv,cv2,os,scipy,pickle,warnings,matplotlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gc\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.stats import norm,skew\n",
        "from itertools import islice\n",
        "!pip install np_utils\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.callbacks import History\n",
        "from keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D,GlobalMaxPooling2D\n",
        "from keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from keras import applications\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "print(os.listdir('../content'))\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "N4bpEHoeU302"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_final_history(history):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
        "    ax[0].set_title('loss')\n",
        "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
        "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
        "    ax[1].set_title('acc')\n",
        "    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n",
        "    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n",
        "    ax[0].legend()\n",
        "    ax[1].legend()"
      ],
      "metadata": {
        "id": "wxd6JjahFM7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from zipfile import ZipFile\n",
        "zf = ZipFile('/content/drive/MyDrive/archive.zip', 'r')\n",
        "zf.extractall('../content/')\n"
      ],
      "metadata": {
        "id": "CmYvXQTs9yjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_preprocessing(img):\n",
        "    resized_image = cv2.resize((cv2.cvtColor(img,cv2.COLOR_RGB2HSV))[:,:,1],(40,40))\n",
        "    return resized_image"
      ],
      "metadata": {
        "id": "FeW7BQg4FR1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "features_directory = '../content/data/'\n",
        "labels_file ='../content/data/driving_log.csv'\n",
        "\n",
        "def Load_training(delta):\n",
        "    logs = []\n",
        "    features = []\n",
        "    labels = []\n",
        "    with open(labels_file, 'rt') as f:\n",
        "        reader = csv.reader(f)\n",
        "        for line in reader:\n",
        "            logs.append(line)\n",
        "        log_labels = logs.pop(0)\n",
        "\n",
        "    for i in range(len(logs)):\n",
        "        for j in range(3):\n",
        "            img_path = logs[i][j]\n",
        "            img_path = features_directory + 'IMG' + (img_path.split('IMG')[1]).strip()\n",
        "            img = plt.imread(img_path)\n",
        "            features.append(image_preprocessing(img))\n",
        "            if j == 0:\n",
        "                labels.append(float(logs[i][3]))\n",
        "            elif j == 1:\n",
        "                labels.append(float(logs[i][3]) + delta)\n",
        "            else:\n",
        "                labels.append(float(logs[i][3]) - delta)\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "delta = 0.2\n",
        "features,labels = Load_training(delta)\n",
        "\n",
        "features = np.array(features).astype('float32')\n",
        "labels = np.array(labels).astype('float32')\n",
        "\n",
        "with open('features','wb') as f:\n",
        "    pickle.dump(features,f,protocol=4)\n",
        "with open('labels','wb') as f:\n",
        "    pickle.dump(labels,f,protocol=4)\n"
      ],
      "metadata": {
        "id": "h_Kb-lE3FTI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f632dbe-683d-4ba5-9d81-99e529b093e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24108, 40, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import layers\n",
        "\n",
        "from keras import models\n",
        "\n",
        "from keras.layers import (Input, Dense, Activation, ZeroPadding2D,\n",
        "BatchNormalization, Flatten, Conv2D, concatenate, Lambda)\n",
        "\n",
        "from keras.layers import (AveragePooling2D, MaxPooling2D, Dropout,\n",
        "GlobalMaxPooling2D, GlobalAveragePooling2D)\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras import regularizers, optimizers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "path = '../content/data/'\n",
        "path = os.path.join(path,'driving_log.csv')\n",
        "\n",
        "data_frame = pd.read_csv(path)\n",
        "center = data_frame[data_frame.columns[0]].values\n",
        "left = data_frame[data_frame.columns[1]].values\n",
        "right = data_frame[data_frame.columns[2]].values\n",
        "steering = data_frame[data_frame.columns[3]].values\n",
        "\n",
        "no_of_examples = len(steering)\n",
        "print(no_of_examples)\n",
        "\n",
        "def random_flip(image, steering_angle):\n",
        "\n",
        "    image = cv2.flip(image, 1)\n",
        "    steering_angle = -steering_angle\n",
        "\n",
        "    return image, steering_angle\n",
        "\n",
        "\n",
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "img_folder = '../content/data/IMG'\n",
        "stear_adjust_factor = 0.2\n",
        "IMAGE_HEIGHT = 100\n",
        "IMAGE_WIDTH = 100\n",
        "\n",
        "for i in range(no_of_examples):\n",
        "\n",
        "    for choice in range(3):\n",
        "\n",
        "        if choice == 0: #Center\n",
        "            img = cv2.imread(os.path.join(img_folder,center[i].split('IMG/')[1]))\n",
        "            steering_angle = steering[i]\n",
        "\n",
        "        elif choice == 1: #Left\n",
        "            img = cv2.imread(os.path.join(img_folder,left[i].split('IMG/')[1]))\n",
        "            steering_angle = steering[i] + stear_adjust_factor\n",
        "\n",
        "        elif choice == 2: #Right\n",
        "            img = cv2.imread(os.path.join(img_folder,right[i].split('IMG/')[1]))\n",
        "            steering_angle = steering[i] - stear_adjust_factor\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)[:,:,1]\n",
        "        img = cv2.resize(img,(IMAGE_HEIGHT,IMAGE_WIDTH))\n",
        "\n",
        "        train_x.append(img)\n",
        "        train_y.append(steering_angle)\n",
        "\n",
        "        flip_img,steering_angle = random_flip(img,steering_angle)\n",
        "\n",
        "        train_x.append(flip_img)\n",
        "        train_y.append(steering_angle)\n",
        "\n",
        "\n",
        "train_x = np.array(train_x)\n",
        "train_x = np.reshape(train_x,[train_x.shape[0],train_x.shape[1],train_x.shape[2],1])\n",
        "\n",
        "train_y = np.array(train_y)\n",
        "train_y = np.reshape(train_y,[train_y.shape[0],1])\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(train_x,train_y,random_state=42,test_size=.20)\n",
        "\n",
        "\n",
        "def model(height,width):\n",
        "\n",
        "    x_input = Input(shape=(height,width,1))\n",
        "\n",
        "    x = Lambda(lambda x: x/127.5-1.0)(x_input)\n",
        "\n",
        "    x = Conv2D(32,(3,3),activation='relu',padding='same')(x_input)\n",
        "\n",
        "    x = Conv2D(32,(3,3),activation='relu',padding='same')(x)\n",
        "    x = MaxPooling2D((2,2),padding='valid')(x)\n",
        "\n",
        "    x = Conv2D(64,(3,3),activation='relu',padding='same')(x)\n",
        "\n",
        "    x = Conv2D(64,(3,3),activation='relu',padding='same')(x)\n",
        "    x = MaxPooling2D((2,2),padding='valid')(x)\n",
        "\n",
        "    x = Conv2D(128,(3,3),activation='relu',padding='same')(x)\n",
        "    x = MaxPooling2D((2,2),padding='valid')(x)\n",
        "\n",
        "    x = Conv2D(128,(3,3),activation='relu',padding='same')(x)\n",
        "    x = MaxPooling2D((2,2),padding='valid')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = Dense(256)(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = Dense(1)(x)\n",
        "\n",
        "    model = Model(inputs=x_input,outputs=x,name='model')\n",
        "\n",
        "    return model\n",
        "\n",
        "model = model(IMAGE_HEIGHT,IMAGE_WIDTH)\n",
        "print(model.summary())\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(loss='mse',\n",
        "             optimizer=opt,\n",
        "             metrics=['mse'])\n",
        "\n",
        "model.summary()\n",
        "history = model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=32,epochs=10)\n",
        "\n",
        "model.save('../content/')\n",
        "\n",
        "pre2=model.evaluate(y_train,y_test,batch_size = 64)\n",
        "\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,100])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,100])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)\n",
        "print(\"Accuracy of model on test data is: \",pre2[1]*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQdOB04pN9_L",
        "outputId": "f7c670c3-b4cd-4d3a-ba5a-7f2cb39f10bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8036\n",
            "(48216, 100, 100, 1)\n",
            "(48216, 1)\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 100, 100, 32)      320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 100, 100, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 50, 50, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 50, 50, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 50, 50, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 25, 25, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 25, 25, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 12, 12, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 12, 12, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 6, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4608)              0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 4608)             18432     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               2359808   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,812,513\n",
            "Trainable params: 2,803,297\n",
            "Non-trainable params: 9,216\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 100, 100, 32)      320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 100, 100, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 50, 50, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 50, 50, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 50, 50, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 25, 25, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 25, 25, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 12, 12, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 12, 12, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 6, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4608)              0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 4608)             18432     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               2359808   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,812,513\n",
            "Trainable params: 2,803,297\n",
            "Non-trainable params: 9,216\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "  58/1206 [>.............................] - ETA: 33:24 - loss: 2.7640 - mse: 2.7640"
          ]
        }
      ]
    }
  ]
}